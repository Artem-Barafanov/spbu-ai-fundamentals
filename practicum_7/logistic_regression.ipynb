{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../spbu-ai-fundamentals/config.yaml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой теме мы поработаем с данными, посвященными определению рака молочной железы на основе различных признаков анализа клеток в биопсии (радиус, кривизна, симметрия). Известно, что этот датасет линейно разделим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\spbu-ai-fundamentals\\\\practicum_7\\\\wdbc\\\\data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Проведите краткий EDA. Есть ли выбросы в данных, какие столбцы коррелируют больше всего, стоит ли преобразоывавть какие-то признаки? Хватит 3-4 графиков или таблиц (но можно больше)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(exclude='object')\n",
    "del num_df['id']\n",
    "del num_df['Unnamed: 32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6,5, figsize=(20,20))\n",
    "axes_flattened = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(list(num_df.columns)):\n",
    "    data_col = df[col].dropna()\n",
    "    if data_col.nunique() <= 1:\n",
    "        continue\n",
    "    sns.boxplot(x='diagnosis', y=col, data=df, ax=axes_flattened[i])\n",
    "    axes_flattened[i].set_title(f'{col}', fontsize=10)\n",
    "    i += 1\n",
    "plt.tight_layout(pad=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Бокс-плоты позволяют увидеть, что очень много признаков значительно отличаются по среднему значению для зколачественных и доброкачественных опухолей. Так что предположительно на тепловой карте будут сильные корреляции. Еще видим, что выбросы действительно есть. А еще: у признаков очень отличается масштаб, то есть они несбалансированы._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6,5, figsize=(20,20))\n",
    "axes_flattened = axes.flatten()\n",
    "i = 0\n",
    "\n",
    "for col in num_df.columns:\n",
    "    data_col = df[col].dropna()\n",
    "    if data_col.nunique() <= 1:\n",
    "        continue\n",
    "    sns.violinplot(x='diagnosis', y=col, data=df, ax=axes_flattened[i])\n",
    "    axes_flattened[i].set_title(f'{col}', fontsize=10)\n",
    "    i+=1\n",
    "plt.tight_layout(pad=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Это (на мой вкус) более приятный вид бокс-плотов._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrplot(df, method=\"pearson\", annot=True, **kwargs):\n",
    "    sns.clustermap(\n",
    "        df.corr(method),\n",
    "        fmt=\".2f\", \n",
    "        cmap='coolwarm',\n",
    "        vmin=-1.0,\n",
    "        vmax=1.0,\n",
    "        method=\"complete\",\n",
    "        annot=annot,\n",
    "        figsize=(20,20),\n",
    "        **kwargs,\n",
    "    )\n",
    "corrplot(num_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Здесь видно: очень много значений гиперкоррелируют. Практически все признаки \"связаны между собой\"._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6,5, figsize=(20,20))\n",
    "axes_flattened = axes.flatten()\n",
    "i = 0\n",
    "\n",
    "for col in num_df.columns:\n",
    "    data_col = df[col].dropna()\n",
    "    if data_col.nunique() <= 1:\n",
    "        continue\n",
    "    for d in df['diagnosis'].unique():\n",
    "        sns.kdeplot(x=df[df['diagnosis'] == d][col], label=d, ax=axes_flattened[i])\n",
    "    axes_flattened[i].set_title(f'{col}', fontsize=10)\n",
    "    axes_flattened[i].legend()\n",
    "    i+=1\n",
    "plt.tight_layout(pad=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Это очень информативный график, он показывает относительную плотность распределения значений признаков. Сразу видны отличия между категориями целевой переменной._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df[num_df.columns].dropna(axis=1)\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(X_scaled)\n",
    "\n",
    "df_pca = pd.DataFrame(components, columns=['PC1', 'PC2'])\n",
    "df_pca['diagnosis'] = df['diagnosis'].values\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='diagnosis')\n",
    "plt.title('PCA: 2D пространство')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Здесь методом главных компонент понизили размерность до двух признаков и видно, что диагнозы действительно хорошо отделимы._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id', 'Unnamed: 32'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = df['diagnosis'].replace({'B': 0, 'M': 1}).astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: выведите, сколько в датасете примеров позитивного и негативного класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['diagnosis'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'diagnosis'\n",
    "features = list(df.columns)\n",
    "features.remove('diagnosis')\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df[[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем обучить логистическую регрессию на этих данных. Обратите внимание, что по умолчанию применяется L2 регуляризация,мы будем строить предсказания без нее. Однако, в качестве упражнения, сравним результаты с масштабированием признаков и без.\n",
    "\n",
    "**Задание**: оцените, насколько сбалансированы признаки по масштабу. Попробуйте ответить до запуска кода, стоит ли их сначала масштабировать и почему. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    'mean': num_df.mean(),\n",
    "    'min': num_df.min(),\n",
    "    'max': num_df.max(),\n",
    "    'range': num_df.max() - num_df.min(),\n",
    "})\n",
    "\n",
    "summary_sorted = summary.sort_values('range', ascending=False)\n",
    "print(\"Признаки с наибольшим разбросом:\")\n",
    "display(summary_sorted[['range']].head())\n",
    "\n",
    "print(\"Минимальный range:\", summary['range'].min())\n",
    "print(\"Максимальный range:\", summary['range'].max())\n",
    "print(\"Отношение max_range / min_range:\", summary['range'].max() / summary['range'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Масштабирование 100% нужно, значения некоторых признакв отличаются на порядки._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без масштабирования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values.reshape(-1), train_size=0.8, shuffle=True)\n",
    "clf = LogisticRegression(penalty=None)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С масштабированием:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values.reshape(-1), train_size=0.8, shuffle=True)\n",
    "clf = LogisticRegression(penalty=None)\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все классификаторы в Sklearn имеют два режима - предсказание лейблов и вероятностей. Предсказание вероятностей дает нам необработанные оценки принадлежности к тому или иному классу. Модель в таком случае возвращает вектор (для каждого семпла) размера N (где N - число классов). \n",
    "\n",
    "**Вопрос**: Какого размера будет предсказание в случае бинарной логистической регрессии? А многоклассовой? Другими словами, в каких случаях негативный класс добавляется как отдельный?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_В случае бинарной логистической регрессии predict_proba(X) вернёт массив с формой (n_samples, 2), а в случае многоклассовой — (n_samples, n_classes).\n",
    "Негативный класс вроде как всегда включается явно._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    'pred': clf.predict(X_test).reshape(-1),\n",
    "    'pred_proba': clf.predict_proba(X_test)[:, 1],\n",
    "    'true': y_test.reshape(-1),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Постройте матрицу предсказаний 100x2 для регрессии с двумя классами, где в каждой строке будут случайные значения. \n",
    "1) Получите из этого оценку принадлежности к классу с помощью сигмоиды и софтмакса. \n",
    "2) Постройте предсказание класса. В случае сигмоиды предсказывайте принадлежность к классу на основе границы, софтмакса - по максимальной вероятности\n",
    "\n",
    "**Вопрос***: как еще можно предсказать класс? Всегда ли нужно брать именно эти функции?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit, softmax\n",
    "np.random.seed(42)\n",
    "logits = np.random.randn(100, 2)\n",
    "\n",
    "sigmoid_probs = expit(logits[:, 1])  # P(class=1)\n",
    "softmax_probs = softmax(logits, axis=1)  # P(class=0), P(class=1)\n",
    "\n",
    "sigmoid_preds = (sigmoid_probs >= 0.5).astype(int)\n",
    "softmax_preds = np.argmax(softmax_probs, axis=1)\n",
    "\n",
    "df_result = pd.DataFrame({\n",
    "    'logit_0': logits[:, 0],\n",
    "    'logit_1': logits[:, 1],\n",
    "    'sigmoid_prob': sigmoid_probs,\n",
    "    'softmax_prob_0': softmax_probs[:, 0],\n",
    "    'softmax_prob_1': softmax_probs[:, 1],\n",
    "    'sigmoid_pred': sigmoid_preds,\n",
    "    'softmax_pred': softmax_preds\n",
    "})\n",
    "\n",
    "print(df_result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики классификации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики на основе лейблов\n",
    "Рассмотрим, какие у нас могут быть тезультаты классификации.\n",
    "\n",
    "* TP (true positive) - правильно предсказали: рак есть, что модель и предсказала\n",
    "* FP (false positive) - неправильно предсказали: рака нет,  а модель предсказала, что есть (1st order error)\n",
    "* FN (false negative) - неправильно предсказали: рак вообще-то есть,  а модель предсказала, что нет (2nd order error)!\n",
    "* TN (true negative) - правильно предсказали: рака нет, что модель и предсказала\n",
    "\n",
    "\n",
    "Pos/Neg - общее количество объектов класса 1/0\n",
    "\n",
    "Метрики:\n",
    "\n",
    "* $ \\text{Accuracy} = \\frac{TP + TN}{Pos+Neg}$ - Доля правильных ответов\n",
    "* $ \\text{Error rate} = 1 -\\text{accuracy}$ - Доля ошибок\n",
    "* $ \\text{Precision} =\\frac{TP}{TP + FP}$ - Точность\n",
    "* $ \\text{Recall} =\\frac{TP}{TP + FN} = \\frac{TP}{Pos}$ - Полнота\n",
    "* $ \\text{F}_\\beta \\text{-score} = (1 + \\beta^2) \\cdot \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}{(\\beta^2 \\cdot \\mathrm{precision}) + \\mathrm{recall}}$ F-мера (часто используют F1-меру, где $\\beta=1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC кривая\n",
    "\n",
    "ROC кривая измеряет насколько хорошо классификатор разделяет два класса. Она построена на предсказании вероятности. Площадь под ней (ROC-AUC) является неплохой оценкой общего качества предсказаний. \n",
    " \n",
    "Пусть $y_{\\rm i}$ - истинная метрка и $\\hat{y}_{\\rm i}$ - прогноз вероятности для $i^{\\rm th}$ объекта.\n",
    "\n",
    "Число положительных и отрицательных объектов: $\\mathcal{I}_{\\rm 1} = \\{i: y_{\\rm i}=1\\}$ and $\\mathcal{I}_{\\rm 0} = \\{i: y_{\\rm i}=0\\}$.\n",
    "\n",
    "Для каждого порогового значения вероятности $\\tau$ считаем True Positive Rate (TPR) и False Positive Rate (FPR):\n",
    "\n",
    "\\begin{equation}\n",
    "TPR(\\tau) = \\frac{1}{I_{\\rm 1}} \\sum_{i \\in \\mathcal{I}_{\\rm 1}} I[\\hat{y}_{\\rm i} \\ge \\tau] = \\frac{TP(\\tau)}{TP(\\tau) + FN(\\tau)} = \\frac{TP(\\tau)}{Pos}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "FPR(\\tau) = \\frac{1}{I_{\\rm 0}} \\sum_{i \\in \\mathcal{I}_{\\rm 0}} I[\\hat{y}_{\\rm i} \\ge \\tau]= \\frac{FP(\\tau)}{FP(\\tau) + TN(\\tau)} = \\frac{FP(\\tau)}{Neg}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=10000, n_features=10, n_informative=5, n_redundant=5, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем для сравнения случайный предикт. Иногда это не худшая стратегия. Если в данных мало сигнала, случайное предсказание может работать лучше ложного."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "random_classifier = DummyClassifier(strategy='uniform', random_state=42).fit(X_train, y_train)\n",
    "y_random = random_classifier.predict_proba(X_test)[:,1]\n",
    "y_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_preds = random_classifier.predict(X_test)\n",
    "random_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "def depict_pr_roc(y_true, y_pred, classifier_name='Some Classifier', ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(11, 5))\n",
    "\n",
    "    print(classifier_name, 'metrics')\n",
    "    PrecisionRecallDisplay.from_predictions(y_true, y_pred, ax=ax[0], name=classifier_name)\n",
    "    print('AUC-PR: %.4f' % average_precision_score(y_true, y_pred))\n",
    "    ax[0].set_title(\"PRC\")\n",
    "    ax[0].set_ylim(0, 1.1)\n",
    "\n",
    "    RocCurveDisplay.from_predictions(y_true, y_pred, ax=ax[1], name=classifier_name)\n",
    "    print('AUC-ROC: %.4f' % roc_auc_score(y_true, y_pred))\n",
    "    ax[1].set_title(\"ROC\")\n",
    "    ax[1].set_ylim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "depict_pr_roc(y_test, y_random, 'Random Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также посчитаем другие метрики на основе лейблов.\n",
    "\n",
    "**Задание:** Дополните код по рассчету метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def quality_metrics_report(y_true, y_pred):\n",
    "\n",
    "    tp = np.sum( (y_true == 1) * (y_pred == 1) )\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    tn = np.sum( (y_true == 0) * (y_pred == 0) )\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    error_rate = 1 - accuracy\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    return [tp, fp, fn, tn, accuracy, error_rate, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe для сравнения\n",
    "# методов классификации по метрикам\n",
    "df_metrics = pd.DataFrame(\n",
    "    columns=['acc', 'er', 'precision', 'recall', 'f1', 'auc_pr', 'roc_auc_score', 'reg_const']\n",
    ")\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_random)\n",
    "# добавление очередной строки с характеристиками метода\n",
    "[tp, fp, fn, tn, accuracy, error_rate, precision, recall, f1] = quality_metrics_report(y_test, random_preds)\n",
    "df_metrics.loc['Random Classifier'] = [\n",
    "      accuracy, error_rate, precision, recall, f1,\n",
    "      average_precision_score(y_test, y_random),\n",
    "      roc_auc_score(y_test, y_random),\n",
    "      0,\n",
    "]\n",
    "\n",
    "# по аналогии результаты следующих экспериментов можно будет собрать в табличку\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_lr_prob = lr.predict_proba(X_test)[:, 1] \n",
    "y_lr_pred = lr.predict(X_test) \n",
    "\n",
    "[tp, fp, fn, tn, accuracy, error_rate, precision_val, recall_val, f1_val] = quality_metrics_report(y_test, y_lr_pred)\n",
    "\n",
    "df_metrics.loc['Logistic Regression'] = [\n",
    "    accuracy,\n",
    "    error_rate,\n",
    "    precision_val,\n",
    "    recall_val,\n",
    "    f1_val,\n",
    "    average_precision_score(y_test, y_lr_prob),\n",
    "    roc_auc_score(y_test, y_lr_prob),\n",
    "    0\n",
    "]\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласуются ли метрики? В чем может быть проблема accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Соберите табличку для разных классификаторов.\n",
    "\n",
    "**Задание**: Постройте график PR-curve, ROC-curve для лучшего из них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# PR-кривая\n",
    "PrecisionRecallDisplay.from_predictions(y_test, y_lr_prob, ax=ax[0], name='Logistic Regression')\n",
    "ax[0].set_title(\"Precision-Recall Curve\")\n",
    "ax[0].set_ylim(0, 1.05)\n",
    "\n",
    "# ROC-кривая\n",
    "RocCurveDisplay.from_predictions(y_test, y_lr_prob, ax=ax[1], name='Logistic Regression')\n",
    "ax[1].set_title(\"ROC Curve\")\n",
    "ax[1].set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:** Постройте таблицу точности для набора данных wbdc. Сделайте по таблице метрик на обучающей и тестовой выборках. В таблице сравните разные преобразования признаков и гиперпараметры (регуляризацию). Можно сделать три-четыре эксперимента. \n",
    "- На каком эксперименте получилось достичь лучшего качества на трейне?\n",
    "- А на тесте?\n",
    "- Переобучается ли модель?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'diagnosis'\n",
    "features = list(df.columns)\n",
    "features.remove('diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df[[target]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values.reshape(-1), train_size=0.8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Четыре эксперимента: в них отличается сила регуляризации и метод масштабирования признаков (или вообще его отсутствие)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "experiments = [\n",
    "    {\"name\": \"No Scaling, C=1.0\", \"scaler\": None, \"C\": 1.0},\n",
    "    {\"name\": \"StandardScaler, C=1.0\", \"scaler\": StandardScaler(), \"C\": 1.0},\n",
    "    {\"name\": \"StandardScaler, C=0.01\", \"scaler\": StandardScaler(), \"C\": 0.01},\n",
    "    {\"name\": \"MinMaxScaler, C=1.0\", \"scaler\": MinMaxScaler(), \"C\": 1.0},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for exp in experiments:\n",
    "    steps = []\n",
    "    if exp[\"scaler\"]:\n",
    "        steps.append((\"scaler\", exp[\"scaler\"]))\n",
    "    steps.append((\"clf\", LogisticRegression(C=exp[\"C\"], max_iter=1000)))\n",
    "    \n",
    "    pipe = Pipeline(steps)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    for split, X, y in [(\"train\", X_train, y_train), (\"test\", X_test, y_test)]:\n",
    "        y_pred = pipe.predict(X)\n",
    "        y_prob = pipe.predict_proba(X)[:, 1]\n",
    "        \n",
    "        results.append({\n",
    "            \"experiment\": exp[\"name\"],\n",
    "            \"split\": split,\n",
    "            \"accuracy\": accuracy_score(y, y_pred),\n",
    "            \"f1\": f1_score(y, y_pred),\n",
    "            \"roc_auc\": roc_auc_score(y, y_prob)\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.pivot(index=\"experiment\", columns=\"split\", values=[\"accuracy\", \"f1\", \"roc_auc\"])\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Если оценивать каечство по f1, то StandardScaler, C=1.0 показал себя лучше всего на train. То же самое и на test. Более сильные переобучения показали No Scaling, C=1.0 и StandardScaler, C=0.01, опять же в первом случае из-за отсутствия масштабирования, а во-втором - из-за слабой регуляризации._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b3714695f2307aafe7da52bf6e53e38bc5469a267534973be7d21c816457eaf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
